{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Trees and Forests\n",
    "\n",
    "In this assignment, you will explore tree-based classification models to implement predictions for broadband deployment, using a combination of available datasets from the Census and the Federal Communications Commission (FCC).\n",
    "\n",
    "You will work with these datasets to understand the nature of broadband deployment across Chicago, as well as what features turn out to be good predictors of broadband deployment. The existence of connectivity in a certain area can also be measured in a variety of ways (e.g., available speed tiers, subscriptions, measured performance), and reported in different ways (e.g., by ISPs, by citizens/subscribers). You will explore how reporting and characteristics vary across different datasets and how this may affect your model.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this assignment, you will learn the following:\n",
    "* The mechanisms of decision trees and bootstrapping methods, including Random Forest classifiers\n",
    "* How to work with various broadband connectivity data (ACS, FCC, etc.)\n",
    "* How to apply tree-based classification models to data (decision tree, Random Forest)\n",
    "* How to take advantage of various characteristics of Random Forest models, such as feature importance\n",
    "* How to evaluate classification models using various metrics and approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tree-Based Models by Hand\n",
    "\n",
    "In this section, you will manually implement a decision tree using entropy and information gain. \n",
    "Please do not use code in your calculations for this section. You may either type your solutions using Markdown, or attach a scanned copy of your hand written solutions in your Canvas file submission. \n",
    "\n",
    "For this section, you will predict the user experience when streaming a video, based on three attributes: the speed that they have purchased from their ISP, the quality of their WiFi Router, and the type of device they are using to stream.\n",
    "\n",
    "| ISP Speed | WiFi Router | Device Type | User Experience |\n",
    "|----------|------------|-----------|----------------|\n",
    "| Fast    | Regular    | Old     | Low            |\n",
    "| Medium   | Regular    | Average | High           |\n",
    "| Slow    | Premium    | New     | Low            |\n",
    "| Fast    | Premium    | New     | High           |\n",
    "| Fast    | Premium    | Average | Low            |\n",
    "| Medium   | Regular    | Old     | High           |\n",
    "| Slow    | Regular    | Old     | High           |\n",
    "| Slow    | Premium    | Average | Low            |\n",
    "| Slow    | Premium    | Average | High           |\n",
    "| Slow    | Regular    | Average | High           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculating Entropy\n",
    "\n",
    "What is the entropy for the User Experience attribute? Were you expecting a result around this number? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Calculating Information Gain\n",
    "\n",
    "What is the information gain on User Experience if you split the observations on the WiFi Router attribute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Building a Simple Decision Tree\n",
    "\n",
    "\n",
    "Construct a simple two-level decision tree that can be used to predict User Experience. Use information gain as your splitting criterion. Feel free to use a greedy approach, recursively splitting on the attribute that gives the greatest information gain at each step.\n",
    "\n",
    "Draw your final tree and include an image of it with your final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading and Exploring Datasets \n",
    "\n",
    "### 2.1 FCC Broadband Map Data\n",
    "\n",
    "In the first part of the lab, you will compile the datasets that you will use in your analysis. Given that the FCC dataset is quite large, we will work with a truncated version of the data for Chicago. We have also included the original source in case you wish to explore the full data yourself. \n",
    "\n",
    "The FCC makes its data for broadband maps available on [its website](https://broadbandmap.fcc.gov). Data is also [available for download](https://broadbandmap.fcc.gov/#/data-download). Internet service providers are required to fill out a \"Form 477\", which reports service offerings in each Census Block.  \n",
    "\n",
    "The specific data that we will use for this lab is from June 2019 in Cook County, IL. We provide the the following code for downloading the data, according to [the API documentation](https://dev.socrata.com/foundry/opendata.fcc.gov/sgz3-kiqt). You should have 794,141 rows. The download should take no more than 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794141, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logrecno</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>frn</th>\n",
       "      <th>providername</th>\n",
       "      <th>dbaname</th>\n",
       "      <th>holdingcompanyname</th>\n",
       "      <th>hoconum</th>\n",
       "      <th>hocofinal</th>\n",
       "      <th>stateabbr</th>\n",
       "      <th>blockcode</th>\n",
       "      <th>techcode</th>\n",
       "      <th>consumer</th>\n",
       "      <th>maxaddown</th>\n",
       "      <th>maxadup</th>\n",
       "      <th>business</th>\n",
       "      <th>maxcirdown</th>\n",
       "      <th>maxcirup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23542275</td>\n",
       "      <td>50860</td>\n",
       "      <td>0003729340</td>\n",
       "      <td>CBTS Technology Solutions LLC</td>\n",
       "      <td>CBTS Technology Solutions LLC</td>\n",
       "      <td>Cincinnati Bell Inc.</td>\n",
       "      <td>130254</td>\n",
       "      <td>Cincinnati Bell Inc.</td>\n",
       "      <td>IL</td>\n",
       "      <td>170318017022031</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23543612</td>\n",
       "      <td>50860</td>\n",
       "      <td>0003729340</td>\n",
       "      <td>CBTS Technology Solutions LLC</td>\n",
       "      <td>CBTS Technology Solutions LLC</td>\n",
       "      <td>Cincinnati Bell Inc.</td>\n",
       "      <td>130254</td>\n",
       "      <td>Cincinnati Bell Inc.</td>\n",
       "      <td>IL</td>\n",
       "      <td>170318030121010</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logrecno provider_id         frn                   providername  \\\n",
       "0  23542275       50860  0003729340  CBTS Technology Solutions LLC   \n",
       "1  23543612       50860  0003729340  CBTS Technology Solutions LLC   \n",
       "\n",
       "                         dbaname    holdingcompanyname hoconum  \\\n",
       "0  CBTS Technology Solutions LLC  Cincinnati Bell Inc.  130254   \n",
       "1  CBTS Technology Solutions LLC  Cincinnati Bell Inc.  130254   \n",
       "\n",
       "              hocofinal stateabbr        blockcode techcode consumer  \\\n",
       "0  Cincinnati Bell Inc.        IL  170318017022031       50        0   \n",
       "1  Cincinnati Bell Inc.        IL  170318030121010       30        0   \n",
       "\n",
       "  maxaddown maxadup business maxcirdown maxcirup  \n",
       "0         0       0        1          0        0  \n",
       "1         0       0        1          0        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"opendata.fcc.gov\", None)\n",
    "\n",
    "# GEOID is the only geographic attribute, so we limit the data to Cook County \n",
    "# Returned as JSON from API / converted to Python list of dictionaries by sodapy \n",
    "results = client.get(\"sgz3-kiqt\", limit=800000, where=\"starts_with(blockcode, '17031')\")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "fcc_df = pd.DataFrame.from_records(results)\n",
    "\n",
    "print(fcc_df.shape)\n",
    "fcc_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, produce the following three maps for the City of Chicago:\n",
    "1. The maximum contractual downstream speed offered by any provider in each Census block group.\n",
    "2. The number of unique ISPs that offer service in each Census block group.\n",
    "3. The number of unique ISPs that offer service at or above 25 Mbps downstream and 3 Mbps upstream in each Census block group. (This is the FCC's definition of broadband Internet access, which you can read about more in the [2019 broadband deployment report](https://docs.fcc.gov/public/attachments/FCC-19-44A1.pdf)). Use contractual downstream and upstream speed.\n",
    "\n",
    "**Note:** Geographic boundaries are only directly available on the Chicago Open Data Portal at the Census block and Census tract level. However, the GeoPandas `dissolve` command can be used to obtain boundaries at the Census block group level. Recall that Census block groups correspond to 12 digits of the FIPS code based on the [Census geography hierarchy](https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MAP 1 HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP 2 HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP 3 HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ACS Data\n",
    "\n",
    "The American Community Survey (ACS) provides data on broadband Internet access subscriptions, as reported by participants. For this lab, we will use the ACS 5-year estimates at the Census block group level for 2018.\n",
    "\n",
    "Use the Census API to perform the following for block groups in the City of Chicago:\n",
    "1. Load ACS data for the following field: \n",
    "    * the percentages of broadband Internet access of any type\n",
    "2. Load ACS data for Total Population, White, Black, and Median Income – and then compute the following: \n",
    "    * the percentage of each Census block group's population that is White and Black; \n",
    "    * the median income for the block gloup; \n",
    "    * the population density of the block group (e.g. in units of population per square kilometer) \n",
    "    \n",
    "Present your answer as a dataframe showing only the first few rows. Some of these computations should be familiar from the previous lab. We've provided code using the `censusdata` package for pulling the necessary ACS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>Internet Total</th>\n",
       "      <th>Broadband</th>\n",
       "      <th>Race Total</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Median Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Block Group 1, Census Tract 8088, Cook County, Illinois: Summary level: 150, state:17&gt; county:031&gt; tract:808800&gt; block group:1</th>\n",
       "      <td>1500000US170318088001</td>\n",
       "      <td>788</td>\n",
       "      <td>690</td>\n",
       "      <td>1738</td>\n",
       "      <td>1538</td>\n",
       "      <td>70</td>\n",
       "      <td>96111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block Group 2, Census Tract 8088, Cook County, Illinois: Summary level: 150, state:17&gt; county:031&gt; tract:808800&gt; block group:2</th>\n",
       "      <td>1500000US170318088002</td>\n",
       "      <td>601</td>\n",
       "      <td>516</td>\n",
       "      <td>1994</td>\n",
       "      <td>1672</td>\n",
       "      <td>39</td>\n",
       "      <td>173646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   GEO_ID  \\\n",
       "Block Group 1, Census Tract 8088, Cook County, ...  1500000US170318088001   \n",
       "Block Group 2, Census Tract 8088, Cook County, ...  1500000US170318088002   \n",
       "\n",
       "                                                    Internet Total  Broadband  \\\n",
       "Block Group 1, Census Tract 8088, Cook County, ...             788        690   \n",
       "Block Group 2, Census Tract 8088, Cook County, ...             601        516   \n",
       "\n",
       "                                                    Race Total  White  Black  \\\n",
       "Block Group 1, Census Tract 8088, Cook County, ...        1738   1538     70   \n",
       "Block Group 2, Census Tract 8088, Cook County, ...        1994   1672     39   \n",
       "\n",
       "                                                    Median Income  \n",
       "Block Group 1, Census Tract 8088, Cook County, ...          96111  \n",
       "Block Group 2, Census Tract 8088, Cook County, ...         173646  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import censusdata\n",
    "\n",
    "# Useful for finding the ACS tables you want \n",
    "# censusdata.search('acs5', 2018, 'label', 'broadband') \n",
    "# censusdata.printtable(censusdata.censustable('acs5', 2018, 'B28011'))\n",
    "\n",
    "# Pull ACS data \n",
    "census_tables = {\n",
    "    'GEO_ID': 'GEO_ID', \n",
    "    'B28011_001E': 'Internet Total', \n",
    "    'B28011_004E': 'Broadband', \n",
    "    'B02001_001E': 'Race Total', \n",
    "    'B02001_002E': 'White', \n",
    "    'B02001_003E': 'Black', \n",
    "    'B19013_001E': 'Median Income'}\n",
    "\n",
    "acs_df = censusdata.download(\"acs5\", \n",
    "                              2018, \n",
    "                              censusdata.censusgeo([(\"state\", \"17\"), \n",
    "                                                    (\"county\", \"031\"),\n",
    "                                                    (\"tract\", \"*\"),\n",
    "                                                    (\"block group\", \"*\")]), \n",
    "                              list(census_tables.keys()))\n",
    "\n",
    "# Rename columns \n",
    "acs_df.rename(columns=census_tables, inplace=True)\n",
    "\n",
    "print(acs_df.shape)\n",
    "acs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Prediction with Tree-Based Models\n",
    "\n",
    "In this part of the assignment, you will use the data and features that you computed to develop tree-based prediction models for broadband Internet deployment at the Census block group level. \n",
    "\n",
    "### 3.1 Decision Trees\n",
    "\n",
    "#### 3.1.1 Training Decison Trees\n",
    "\n",
    "First, train a decision tree classifier to predict if a Census block group has broadband Internet access or not (i.e., at least one ISP that offers service at or above 25 Mbps downstream and 3 Mbps upstream). Tune your classifier with a hyperparameter grid and use k-fold cross validation. \n",
    "\n",
    "In the previous lab, you were asked to construct hyperparameter grids and manually send data through the pipeline. For this lab, you may use scikit-learn's inbuilt `Pipeline` and `GridSearchCV` objects to simplify this step. \n",
    "\n",
    "Some additional notes on training:\n",
    "\n",
    "- Use `random_state=0` when both splitting your data and training your classifiers.\n",
    "- Given the size of this dataset, it will be sufficient to forgo the validation set and only separate your data into training and testing sets (i.e., use `sklearn.model_selection.test_train_split`)\n",
    "- Your classifier should use the following features:\n",
    "    - The ACS population characteristics from Section 2.2 (percentage of population that is White and Black, median income, population density)\n",
    "    - The number of ISPs serving that block group\n",
    "- Tune your classifier with a hyperparameter grid, using the following hyperparameter options:\n",
    "    - `criterion`: `gini` or `entropy`\n",
    "    - `max_depth`: 1, 3, 5\n",
    "    - `min_samples_split`: 2, 5, 10\n",
    "- Use K-fold cross validation with `k = 10`, using accuracy as your scoring metric.\n",
    "- For evaluation metrics, print accuracy, precision, and recall on the test set for each hyperparameter combination.\n",
    "\n",
    "Print a dataframe summarizing your grid search results. This should have one row for each classifier that you trained (18 total rows) specifying the hyperparamters for that classifier along with its evaluation metrics averaged across the folds (accuracy, precision, and recall). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Evaluation I: Interpreting Trees\n",
    "\n",
    "Print the tree with the highest average test accuracy. Note that `sklearn.tree.export_graphviz` may be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the most important feature in the tree that yielded the highest accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Evaluation II: Confusion Matrices and Precision-Recall Curves\n",
    "\n",
    "For all questions in this section, use the decision tree from above that yielded the highest average accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the confusion matrix for this decision tree. Then use the output of this confusion matrix to manually calculate the following:\n",
    "\n",
    "1. What is the test precision for this tree?\n",
    "2. What is the test recall for this tree?\n",
    "3. What is the test F1 score for this tree? \n",
    "\n",
    "After manually computing these metrics, use the built-in `scikit-learn.metrics` functions to verify your answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the precision-recall curve for this decision tree. Then answer the following questions:\n",
    "\n",
    "1. Describe what you observe in the precision-recall curve in plain language.\n",
    "2. Does it make sense for precision to decrease as recall increases? Why or why not? \n",
    "3. Can you identify a 'sweet spot' in the graph? (i.e., a threshold that balances nicely precision and recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Subsetting Features\n",
    "Note that the number of ISPs is closely (and directly) related to the predicted outcome. Suppose you no longer have access to the FCC data. Re-run your decision tree classification using just the ACS demographic features. How does this model perform compared to the model including the number of ISPs as a predictor? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forests\n",
    "\n",
    "#### 3.2.1 Training Random Forests\n",
    "\n",
    "Next, train a Random Forest classifier to predict broadband Internet deployment. As before, tune your classifier with a hyperparameter grid and use k-fold cross validation. Again, print a dataframe summarizing the classifiers, the hyperparameters for each classifier, and their respective evaluation metrics.\n",
    "\n",
    "As with the previous section: \n",
    "- You may use scikit-learn's inbuilt `Pipeline` and `GridSearchCV` functions if you prefer.\n",
    "- Use `random_state=0` when both splitting your data and training your classifiers.\n",
    "- Given the size of this dataset, it will be sufficient to forgo the validation set and only separate your data into training and testing sets (i.e., use `sklearn.model_selection.test_train_split`)\n",
    "- Your classifier should use the following features:\n",
    "    - The ACS population characteristics from Section 2.2 (percentage of population that is White and Black, median income, population density)\n",
    "    - The number of ISPs serving that block group\n",
    "- Tune your classifier with a hyperparameter grid, using the following hyperparameter options (note the differences for Random Forests):\n",
    "    - `n_estimators`: 100, 1000, 5000\n",
    "    - `criterion`: `gini` or `entropy`\n",
    "    - `max_depth`: 1, 3, 5\n",
    "    - `min_samples_split`: 2, 5, 10\n",
    "- Use K-fold cross validation with `k = 10`, using accuracy as your scoring metric.\n",
    "- For evaluation metrics, print accuracy, precision, and recall on the test set for each hyperparameter combination.\n",
    "\n",
    "**Note:** This will take noticeably longer than training the single decision tree, but should not exceed 40 minutes. We highly recommend creating a smaller sample of this data to work with while you test your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Evaluation I: Interpreting Random Forests\n",
    "\n",
    "Identify the Random Forest with the highest average test accuracy. Create a plot showing feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Evaluation II: Confusion Matrices and Precision Recall Curves\n",
    "\n",
    "For all questions in this section, use the Random Forest classifier that yielded the highest average accuracy. \n",
    "\n",
    "Report the confusion matrix for this Random Forest classifier using the test data. Then manually calculate the following (and feel free to then check your work with the built-in functions):\n",
    "\n",
    "1. What is the test precision for this classifier?\n",
    "2. What is the test recall for this classifier?\n",
    "3. What is the test F1 score for this classifier? \n",
    "\n",
    "How do these figures compare to the test metrics for the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the precision-recall curve for this Random Forest. On the same axes, plot the precision-recall curve for the decision tree that you previously plotted in Section 3.1.3. How do they compare? Which would you choose if you wanted to maximize precision? What if you wanted to maximize recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Policy Applications and Model Selection\n",
    "\n",
    "Imagine you have been hired by the City of Chicago, who is administering a survey about broadband quality. However, they do not know which block groups have broadband and must choose a model to predict broadband deployment. \n",
    "\n",
    "1. It is important for you to reach as many block groups with broadband as possible without visiting every single block group. Of the classifiers you trained above, which should you use to predict broadband deployment in this situation? Why?\n",
    "2. Budget cuts have struck! Priorities have shifted, and you are now told that you can only survey a small number of block groups. You are not worried about representativeness, and your main goal is to avoid wasting resources by visiting block groups that do not have broadband. Which classifier do you use now? Why?\n",
    "3. You find out only after training that your population density data was in units of people per square mile, not people per square kilometer, meaning that your data would need to be rescaled to be properly interpreted. Do you now need to retrain your model with the rescaled data to get an updated set of predictions? Why or why not?\n",
    "4. The City of Chicago is interested in better understanding the predictive features in your model. Why do you think the number of ISP providers and population density are important predictors? \n",
    "\n",
    "There is a deep policy debate around broadband access related to the role of public investment, public-private-partnerships, and subsidies. This includes a discussion of 'rate-of-return' carriers and what ISPs should be allowed to charge for broadband access in rural areas. For further reading, see [this discussion](https://www.usac.org/high-cost/resources/rules-orders/rate-of-return-reform-order/) on rate-of-return reform and this [FCC briefing](https://docs.fcc.gov/public/attachments/FCC-19-77A1.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Working with Thresholds\n",
    "\n",
    "So far, we've been using GridSearch and Cross-Validation (`GridSearchCV`) to find the best models. Internally, this method is running `predict` on each validation fold, computing the evaluation metrics (accuracy, precision, etc.) for each fold and returning the average for the metrics. Recall that `predict` uses 0.5 as the default classification threshold, meaning every observation with a probability score above 0.5 is classified as True.\n",
    "\n",
    "In many cases, `predict` is not ideal. Instead, we might want to choose a classification threshold ourselves, rather than use the default 0.5 cutoff. The threshold might be a fixed value (say every observation with a probability above 0.7 receives a predicted label of True). Alternatively, the threshold might be based on a percentage of the total observations (e.g. the top 10% of observations with the highest probability scores will be labelled as True, while the rest will be labelled as False). Which approach to choose will depend on your policy problem. In this exercise, we will explore the effect of using custom thresholds through both approaches. \n",
    "\n",
    "Use the best Random Forest classifier identified in the previous section to output prediction probabilities for your testing dataset. Note that you will need to use `predict_proba` rather than `predict` to get these probability scores. Be sure that you understand what the output of `predict_proba` returns and its dimensions. Then, compute precision and recall for different thresholds. \n",
    "\n",
    "#### 3.4.1 Thresholds I: Fixed Values Approach\n",
    "Use the following fixed values to convert probability scores (the output of `predict_proba`) into binary predictions: 0, 0.3, 0.5, 0.7, 0.9. Output a table summarizing the precision and recall at each of these thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Thresholds II: Percentage Approach\n",
    "\n",
    "Now, use the percentage-based approach using the following threshold percentages: 1%, 5%, 10%, 20%, 50% 100%. \n",
    "\n",
    "Using the 1% threshold, for example, you would need to output probability scores for each observation, sort these probabilities in descending order based on this score, and then assign the top 1% True (and the bottom 99% False). If your dataset had 1,000 observations, that would mean that just 10 observations would be marked True. \n",
    "\n",
    "Again, output a table summarizing the precision and recall at each of these thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Summarizing Thresholds\n",
    "\n",
    "Describe what you observed in the two summary tables above. How do precision and recall change when adjusting the thresholds using the two approaches? Are these results consistent with your precision-recall curves? Discuss a situation when using a threshold approach would make sense when evaluating classification models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
